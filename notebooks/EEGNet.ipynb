{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "CE = np.load('/workspace/data/EEG/data/epochs/A-epo.npy')\n",
    "lab = np.load(\"/workspace/data/EEG/data/epochs/A-labels.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "l = lab-1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "def EEGNet(nb_classes, Chans = 64, Samples = 128,\n",
    "             dropoutRate = 0.5, kernLength = 64, F1 = 8,\n",
    "             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "    \"\"\" Keras Implementation of EEGNet\n",
    "    http://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta\n",
    "    Note that this implements the newest version of EEGNet and NOT the earlier\n",
    "    version (version v1 and v2 on arxiv). We strongly recommend using this\n",
    "    architecture as it performs much better and has nicer properties than\n",
    "    our earlier version. For example:\n",
    "\n",
    "        1. Depthwise Convolutions to learn spatial filters within a\n",
    "        temporal convolution. The use of the depth_multiplier option maps\n",
    "        exactly to the number of spatial filters learned within a temporal\n",
    "        filter. This matches the setup of algorithms like FBCSP which learn\n",
    "        spatial filters within each filter in a filter-bank. This also limits\n",
    "        the number of free parameters to fit when compared to a fully-connected\n",
    "        convolution.\n",
    "\n",
    "        2. Separable Convolutions to learn how to optimally combine spatial\n",
    "        filters across temporal bands. Separable Convolutions are Depthwise\n",
    "        Convolutions followed by (1x1) Pointwise Convolutions.\n",
    "\n",
    "\n",
    "    While the original paper used Dropout, we found that SpatialDropout2D\n",
    "    sometimes produced slightly better results for classification of ERP\n",
    "    signals. However, SpatialDropout2D significantly reduced performance\n",
    "    on the Oscillatory dataset (SMR, BCI-IV Dataset 2A). We recommend using\n",
    "    the default Dropout in most cases.\n",
    "\n",
    "    Assumes the input signal is sampled at 128Hz. If you want to use this model\n",
    "    for any other sampling rate you will need to modify the lengths of temporal\n",
    "    kernels and average pooling size in blocks 1 and 2 as needed (double the\n",
    "    kernel lengths for double the sampling rate, etc). Note that we haven't\n",
    "    tested the model performance with this rule so this may not work well.\n",
    "\n",
    "    The model with default parameters gives the EEGNet-8,2 model as discussed\n",
    "    in the paper. This model should do pretty well in general, although it is\n",
    "\tadvised to do some model searching to get optimal performance on your\n",
    "\tparticular dataset.\n",
    "    We set F2 = F1 * D (number of input filters = number of output filters) for\n",
    "    the SeparableConv2D layer. We haven't extensively tested other values of this\n",
    "    parameter (say, F2 < F1 * D for compressed learning, and F2 > F1 * D for\n",
    "    overcomplete). We believe the main parameters to focus on are F1 and D.\n",
    "    Inputs:\n",
    "\n",
    "      nb_classes      : int, number of classes to classify\n",
    "      Chans, Samples  : number of channels and time points in the EEG data\n",
    "      dropoutRate     : dropout fraction\n",
    "      kernLength      : length of temporal convolution in first layer. We found\n",
    "                        that setting this to be half the sampling rate worked\n",
    "                        well in practice. For the SMR dataset in particular\n",
    "                        since the data was high-passed at 4Hz we used a kernel\n",
    "                        length of 32.\n",
    "      F1, F2          : number of temporal filters (F1) and number of pointwise\n",
    "                        filters (F2) to learn. Default: F1 = 8, F2 = F1 * D.\n",
    "      D               : number of spatial filters to learn within each temporal\n",
    "                        convolution. Default: D = 2\n",
    "      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "\n",
    "    input1   = Input(shape = (Chans, Samples, 1))\n",
    "\n",
    "    ##################################################################\n",
    "    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
    "                                   input_shape = (Chans, Samples, 1),\n",
    "                                   use_bias = False)(input1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = DepthwiseConv2D((Chans, 1), use_bias = False,\n",
    "                                   depth_multiplier = D,\n",
    "                                   depthwise_constraint = max_norm(1.))(block1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = AveragePooling2D((1, 4))(block1)\n",
    "    block1       = dropoutType(dropoutRate)(block1)\n",
    "\n",
    "    block2       = SeparableConv2D(F2, (1, 16),\n",
    "                                   use_bias = False, padding = 'same')(block1)\n",
    "    block2       = BatchNormalization()(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = AveragePooling2D((1, 8))(block2)\n",
    "    block2       = dropoutType(dropoutRate)(block2)\n",
    "\n",
    "    flatten      = Flatten(name = 'flatten')(block2)\n",
    "\n",
    "    dense        = Dense(nb_classes, name = 'dense',\n",
    "                         kernel_constraint = max_norm(norm_rate))(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "\n",
    "    return Model(inputs=input1, outputs=softmax)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "#from CNN1 import CNN1\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#from tensorflow import set_random_seed\n",
    "from sklearn.model_selection import *\n",
    "from utils import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_subject_models(data, labels, modelpath, subject):\n",
    "    \"\"\"\n",
    "    Trains and evaluates EEgNet for a given subject in the P300 Speller database\n",
    "    using repeated stratified K-fold cross validation.\n",
    "    \"\"\"\n",
    "    n_sub = data.shape[0]\n",
    "    n_ex_sub = data.shape[1]\n",
    "    n_samples = data.shape[2]\n",
    "    n_channels = data.shape[3]\n",
    "    aucs = np.zeros(5 * 10)\n",
    "    print(\"Training for subject {0}: \".format(subject))\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 10, random_state = 123)\n",
    "    for k, (t, v) in enumerate(cv.split(data[subject], labels[subject])):\n",
    "        X_train, y_train, X_test, y_test = data[subject, t, :, :], labels[subject, t], data[subject, v, :, :], labels[subject, v]\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, shuffle = True, random_state = 456)\n",
    "        print('Partition {0}: X_train = {1}, X_valid = {2}, X_test = {3}'.format(k, X_train.shape, X_valid.shape, X_test.shape))\n",
    "\n",
    "        # channel-wise feature standarization\n",
    "        sc = EEGChannelScaler(n_channels = n_channels)\n",
    "        X_train = np.swapaxes(sc.fit_transform(X_train)[:, np.newaxis, :], 2, 3)\n",
    "        X_valid = np.swapaxes(sc.transform(X_valid)[:, np.newaxis, :], 2, 3)\n",
    "        X_test = np.swapaxes(sc.transform(X_test)[:, np.newaxis, :], 2, 3)\n",
    "\n",
    "        #X_train = sc.fit_transform(X_train)\n",
    "        #X_valid = sc.transform(X_valid)\n",
    "        #X_test = sc.transform(X_test)\n",
    "\n",
    "        model = EEGNet(2, Chans = n_channels, Samples = n_samples)\n",
    "        print(model.summary())\n",
    "        model.compile(optimizer = 'adam', loss = 'categorical_crossentropy')\n",
    "\n",
    "        # Early stopping setting also follows EEGNet (Lawhern et al., 2018)\n",
    "        es = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 50, restore_best_weights = True)\n",
    "        history = model.fit(X_train,\n",
    "                            to_categorical(y_train),\n",
    "                            batch_size = 256,\n",
    "                            epochs = 200,\n",
    "                            validation_data = (X_valid, to_categorical(y_valid)),\n",
    "                            callbacks = [es])\n",
    "\n",
    "        proba_test = model.predict(X_test)\n",
    "        aucs[k] = roc_auc_score(y_test, proba_test[:, 1])\n",
    "        print('S{0}, P{1} -- AUC: {2}'.format(subject, k, aucs[k]))\n",
    "        K.clear_session()\n",
    "\n",
    "    np.savetxt(modelpath + '/s' + str(subject) + '_aucs.npy', aucs)\n",
    "    return aucs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "rCE = CE.reshape(CE.shape[0], CE.shape[2], CE.shape[3], CE.shape[1])\n",
    "tCE = np.transpose(CE,(0,2,3,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "l = lab-1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "(8, 4200, 8, 257)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CE.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for subject 0: \n",
      "Partition 0: X_train = (2688, 8, 257), X_valid = (672, 8, 257), X_test = (840, 8, 257)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"average_pooling2d_3\" (type AveragePooling2D).\n\nNegative dimension size caused by subtracting 8 from 2 for '{{node average_pooling2d_3/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 1, 8, 1], padding=\"VALID\", strides=[1, 1, 8, 1]](Placeholder)' with input shapes: [?,1,2,16].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 1, 2, 16), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_173033/1597085623.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mauc_sub\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevaluate_subject_models\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mCE\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ml\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"/workspace/data/EEG/models/\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_173033/4060274763.py\u001B[0m in \u001B[0;36mevaluate_subject_models\u001B[0;34m(data, labels, modelpath, subject)\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0;31m#X_test = sc.transform(X_test)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 42\u001B[0;31m         \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mEEGNet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mChans\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mn_channels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSamples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mn_samples\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     43\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msummary\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moptimizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'adam'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'categorical_crossentropy'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_173033/1072804432.py\u001B[0m in \u001B[0;36mEEGNet\u001B[0;34m(nb_classes, Chans, Samples, dropoutRate, kernLength, F1, D, F2, norm_rate, dropoutType)\u001B[0m\n\u001B[1;32m     98\u001B[0m     \u001B[0mblock2\u001B[0m       \u001B[0;34m=\u001B[0m \u001B[0mBatchNormalization\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mblock2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     99\u001B[0m     \u001B[0mblock2\u001B[0m       \u001B[0;34m=\u001B[0m \u001B[0mActivation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'elu'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mblock2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 100\u001B[0;31m     \u001B[0mblock2\u001B[0m       \u001B[0;34m=\u001B[0m \u001B[0mAveragePooling2D\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m8\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mblock2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    101\u001B[0m     \u001B[0mblock2\u001B[0m       \u001B[0;34m=\u001B[0m \u001B[0mdropoutType\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdropoutRate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mblock2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/workspace/data/EEG/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m       \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m       \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/workspace/data/EEG/.venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36m_create_c_op\u001B[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001B[0m\n\u001B[1;32m   2011\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mInvalidArgumentError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2012\u001B[0m     \u001B[0;31m# Convert to ValueError for backwards compatibility.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2013\u001B[0;31m     \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2014\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2015\u001B[0m   \u001B[0;32mreturn\u001B[0m \u001B[0mc_op\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Exception encountered when calling layer \"average_pooling2d_3\" (type AveragePooling2D).\n\nNegative dimension size caused by subtracting 8 from 2 for '{{node average_pooling2d_3/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 1, 8, 1], padding=\"VALID\", strides=[1, 1, 8, 1]](Placeholder)' with input shapes: [?,1,2,16].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 1, 2, 16), dtype=float32)"
     ]
    }
   ],
   "source": [
    "auc_sub = evaluate_subject_models(CE, l, \"/workspace/data/EEG/models/\", 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for subject 0: \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [8, 4200]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3426379/180281053.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mauc_resub\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevaluate_subject_models\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrCE\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ml\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"/workspace/data/EEG/models/\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_3426379/4060274763.py\u001B[0m in \u001B[0;36mevaluate_subject_models\u001B[0;34m(data, labels, modelpath, subject)\u001B[0m\n\u001B[1;32m     25\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Training for subject {0}: \"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msubject\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m     \u001B[0mcv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRepeatedStratifiedKFold\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_splits\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_repeats\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m123\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msubject\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msubject\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m         \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msubject\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msubject\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msubject\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msubject\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m         \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_valid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_valid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshuffle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m456\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/workspace/data/EEG/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001B[0m in \u001B[0;36msplit\u001B[0;34m(self, X, y, groups)\u001B[0m\n\u001B[1;32m   1409\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_repeats\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1410\u001B[0m             \u001B[0mcv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrng\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcvargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1411\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mtrain_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_index\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgroups\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1412\u001B[0m                 \u001B[0;32myield\u001B[0m \u001B[0mtrain_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_index\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1413\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/workspace/data/EEG/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001B[0m in \u001B[0;36msplit\u001B[0;34m(self, X, y, groups)\u001B[0m\n\u001B[1;32m    328\u001B[0m             \u001B[0mThe\u001B[0m \u001B[0mtesting\u001B[0m \u001B[0mset\u001B[0m \u001B[0mindices\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mthat\u001B[0m \u001B[0msplit\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    329\u001B[0m         \"\"\"\n\u001B[0;32m--> 330\u001B[0;31m         \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgroups\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mindexable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgroups\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    331\u001B[0m         \u001B[0mn_samples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_num_samples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    332\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_splits\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mn_samples\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/workspace/data/EEG/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mindexable\u001B[0;34m(*iterables)\u001B[0m\n\u001B[1;32m    376\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    377\u001B[0m     \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0m_make_indexable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mX\u001B[0m \u001B[0;32min\u001B[0m \u001B[0miterables\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 378\u001B[0;31m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    379\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    380\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/workspace/data/EEG/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_consistent_length\u001B[0;34m(*arrays)\u001B[0m\n\u001B[1;32m    330\u001B[0m     \u001B[0muniques\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlengths\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    331\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muniques\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 332\u001B[0;31m         raise ValueError(\n\u001B[0m\u001B[1;32m    333\u001B[0m             \u001B[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    334\u001B[0m             \u001B[0;34m%\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ml\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0ml\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlengths\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [8, 4200]"
     ]
    }
   ],
   "source": [
    "auc_resub = evaluate_subject_models(rCE, l, \"/workspace/data/EEG/models/\", 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tCE.shape[3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 128, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 64, 128, 8)        512       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64, 128, 8)       32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " depthwise_conv2d (Depthwise  (None, 1, 128, 16)       1024      \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1, 128, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1, 128, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 1, 32, 16)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 32, 16)         0         \n",
      "                                                                 \n",
      " separable_conv2d (Separable  (None, 1, 32, 16)        512       \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1, 32, 16)        64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1, 32, 16)         0         \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 1, 4, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 4, 16)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 130       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,338\n",
      "Trainable params: 2,258\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 22:00:28.312707: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-17 22:00:29.366724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 141 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2022-03-17 22:00:29.379765: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 141.25M (148111360 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "model = EEGNet(nb_classes=2)\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}